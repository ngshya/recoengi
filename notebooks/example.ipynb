{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import sys\nsys.path.append('../')\nsys.path.append('.')\nimport recoengi\nimport recoengi.cf as cf\n\nimport pandas as pd\nfrom scipy import sparse\nimport numpy as np\nfrom sklearn import metrics\nimport logging\nlogging.basicConfig(level=logging.DEBUG, format=\"%(levelname)s %(asctime)s %(message)s\")"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"dtf_ratings = pd.read_csv(\"sampledata/ml-latest-small/ratings.csv\", usecols=[\"userId\", \"movieId\", \"rating\"])\ndtf_tmp = dtf_ratings.groupby([\"movieId\"]).agg({\"rating\": \"count\"}).reset_index(drop=False)\ndtf_tmp = dtf_tmp.loc[dtf_tmp.rating > 3,:]\ndtf_ratings = dtf_ratings.loc[dtf_ratings.movieId.isin(dtf_tmp.movieId),:]\n\ndtf_tmp = pd.DataFrame({\"movieId\": dtf_ratings.movieId.unique()})\ndtf_tmp = dtf_tmp.reset_index(drop = False)\ndtf_tmp = dtf_tmp.rename({\"index\": \"movieId_new\"}, axis = 1)\ndtf_ratings = pd.merge(dtf_ratings, dtf_tmp, on = [\"movieId\"], how = \"left\").drop([\"movieId\"], axis=1).rename({\"movieId_new\": \"movieId\"}, axis=1)\ndtf_ratings.userId = dtf_ratings.userId-1\ndtf_ratings.rating = (dtf_ratings.rating >= 3) + 0.0\n\ntmp_bln_split = np.random.choice([True, False], size=dtf_ratings.shape[0], replace=True, p=[0.8, 0.2])\ndtf_train = dtf_ratings.loc[tmp_bln_split, [\"userId\", \"movieId\", \"rating\"]]\ndtf_test = dtf_ratings.loc[~tmp_bln_split, [\"userId\", \"movieId\", \"rating\"]]\n\nM = sparse.csr_matrix((dtf_train.rating, (dtf_train.userId, dtf_train.movieId)))"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"DEBUG 2019-10-13 13:07:11,394 M matrix has shape 610x4180.\nDEBUG 2019-10-13 13:07:11,396 B matrix has shape 610x4180.\nDEBUG 2019-10-13 13:07:11,410 B matrix has sparsity 2.37665699270531%.\nDEBUG 2019-10-13 13:07:11,412 Computing the similarity matrix S ...\nDEBUG 2019-10-13 13:07:11,435 S matrix has shape 610x610.\nDEBUG 2019-10-13 13:07:11,436 Computing the matrix SNORMALIZED ...\nDEBUG 2019-10-13 13:07:11,438 Computing the matrix SCORES ...\nDEBUG 2019-10-13 13:07:11,480 SCORES matrix has shape 610x4180.\nDEBUG 2019-10-13 13:07:11,481 Computing the matrix AMOUNTS ...\nDEBUG 2019-10-13 13:07:11,521 AMOUNTS matrix has shape 610x4180.\nDEBUG 2019-10-13 13:07:11,521 Computing the performances ...\nDEBUG 2019-10-13 13:07:11,648 Average global scores difference: 0.05077722274294556.\nDEBUG 2019-10-13 13:07:11,649 Average positive scores difference: 0.7474164850980024.\nWARNING 2019-10-13 13:07:11,649 The scores model could not perform better than a random model! Further tests needed!\nDEBUG 2019-10-13 13:07:11,803 Average global amounts difference: 0.05077722274294556.\nDEBUG 2019-10-13 13:07:11,803 Average positive amounts difference percentage: 74.74164850980024%.\nDEBUG 2019-10-13 13:07:11,804 Average positive amounts difference percentage of a random model: 74.74164850980021%.\nWARNING 2019-10-13 13:07:11,804 The amounts model could not perform better than a random model! Further tests needed!\n"}],"source":"cfm = cf.CFM(M)\ncfm.computeEverything(bln_bin=False, bln_norm=True, flt_ths=0.01, ntop=64, flt_lb=-1)"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"dtf_pred = pd.DataFrame(pd.Series(dict(cfm.SCORES.todok().items()))).reset_index(drop=False)\ndtf_pred.columns = [\"userId\", \"movieId\", \"predicted_score\"]\ndtf_train = pd.merge(dtf_train, dtf_pred, on=[\"userId\", \"movieId\"], how=\"inner\")\ndtf_test = pd.merge(dtf_test, dtf_pred, on=[\"userId\", \"movieId\"], how=\"inner\")"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"AUC on training set: 0.6746369175263351.\nAUC on test set: 0.6596552122483741.\n"}],"source":"fpr, tpr, thresholds = metrics.roc_curve(y_true=dtf_train.rating+1, y_score=dtf_train.predicted_score, pos_label=2)\nprint(\"AUC on training set: \" + str(metrics.auc(fpr, tpr)) + \".\")\nfpr, tpr, thresholds = metrics.roc_curve(y_true=dtf_test.rating+1, y_score=dtf_test.predicted_score, pos_label=2)\nprint(\"AUC on test set: \" + str(metrics.auc(fpr, tpr)) + \".\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}